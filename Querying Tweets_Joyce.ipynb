{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Twitterscrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open Anaconda command and type \"pip install twitterscrapper\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Libraries and Querying Tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: {'User-Agent': 'Mozilla/5.0 (compatible, MSIE 11, Windows NT 6.3; Trident/7.0; rv:11.0) like Gecko'}\n",
      "INFO: queries: ['cibc since:2019-01-01 until:2019-01-26', 'cibc since:2019-01-26 until:2019-02-20', 'cibc since:2019-02-20 until:2019-03-17', 'cibc since:2019-03-17 until:2019-04-12', 'cibc since:2019-04-12 until:2019-05-07', 'cibc since:2019-05-07 until:2019-06-01', 'cibc since:2019-06-01 until:2019-06-27', 'cibc since:2019-06-27 until:2019-07-22', 'cibc since:2019-07-22 until:2019-08-16', 'cibc since:2019-08-16 until:2019-09-11']\n",
      "INFO: Got 3522 tweets (3522 new).\n",
      "INFO: Got 7112 tweets (3590 new).\n",
      "INFO: Got 11015 tweets (3903 new).\n",
      "INFO: Got 14956 tweets (3941 new).\n",
      "INFO: Got 18963 tweets (4007 new).\n",
      "INFO: Got 23028 tweets (4065 new).\n",
      "INFO: Got 27318 tweets (4290 new).\n",
      "INFO: Got 32016 tweets (4698 new).\n",
      "INFO: Got 36852 tweets (4836 new).\n",
      "INFO: Got 41751 tweets (4899 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Querying Ended--\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import codecs,json\n",
    "from twitterscraper import query_tweets\n",
    "\n",
    "# Set up date range for the extraction\n",
    "begindate = dt.date(2019,1,1)\n",
    "enddate = dt.date.today() - dt.timedelta(days=1)\n",
    "\n",
    "# Querying tweets using twitterscraper's query_tweets\n",
    "# Query_tweets function:\n",
    "'''\n",
    "query_tweets(query = args.query, limit = args.limit,\n",
    "                              begindate = args.begindate, enddate = args.enddate,\n",
    "                              poolsize = args.poolsize, lang = args.lang)\n",
    "'''\n",
    "\n",
    "list_of_tweets = query_tweets(\"cibc\", limit = None, begindate = begindate, enddate = enddate, poolsize = 10, lang='en')\n",
    "list_of_encoded_tweets = [] # create empty list to save multiple tweets which is type of dictionary\n",
    "\n",
    "for tweets in list_of_tweets:\n",
    "    tweets.timestamp = dt.datetime.strftime(tweets.timestamp, '%Y-%m-%d %H:%M:%S')\n",
    "    list_of_encoded_tweets.append(vars(tweets))\n",
    "\n",
    "print('--Querying Ended--')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Output as DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         username           fullname              user_id  \\\n",
      "0             BMO                BMO            222249603   \n",
      "1      daveaurkov         daveaurkov  1068479286892523520   \n",
      "2  JethroOfCanada  JethroTheCanadian           2726878401   \n",
      "3             BMO                BMO            222249603   \n",
      "4             BMO                BMO            222249603   \n",
      "\n",
      "              tweet_id                                   tweet_url  \\\n",
      "0  1162150952390074368             /BMO/status/1162150952390074368   \n",
      "1  1162150214058356739      /daveaurkov/status/1162150214058356739   \n",
      "2  1162149984197914630  /JethroOfCanada/status/1162149984197914630   \n",
      "3  1162142804895850496             /BMO/status/1162142804895850496   \n",
      "4  1162142734846763009             /BMO/status/1162142734846763009   \n",
      "\n",
      "             timestamp  timestamp_epochs  replies  retweets  likes  \\\n",
      "0  2019-08-15 23:55:53        1565913353        0         0      0   \n",
      "1  2019-08-15 23:52:57        1565913177        0         0      1   \n",
      "2  2019-08-15 23:52:02        1565913122        1         0      0   \n",
      "3  2019-08-15 23:23:30        1565911410        0         0      0   \n",
      "4  2019-08-15 23:23:14        1565911394        0         0      0   \n",
      "\n",
      "   is_retweet retweeter_username retweeter_userid retweet_id  \\\n",
      "0           0                                                  \n",
      "1           0                                                  \n",
      "2           0                                                  \n",
      "3           0                                                  \n",
      "4           0                                                  \n",
      "\n",
      "                                                text  \\\n",
      "0  Hello Jethro, I'm Ryan. I'd like to know more ...   \n",
      "1  Wonder how @scottbrison got that @BMO job?   A...   \n",
      "2  @BMO is the worst bank on planet earth.    Thi...   \n",
      "3  Here's that link if you want to send a number:...   \n",
      "4  As a final alternative, if you are logged into...   \n",
      "\n",
      "                                                html  \n",
      "0  <p class=\"TweetTextSize js-tweet-text tweet-te...  \n",
      "1  <p class=\"TweetTextSize js-tweet-text tweet-te...  \n",
      "2  <p class=\"TweetTextSize js-tweet-text tweet-te...  \n",
      "3  <p class=\"TweetTextSize js-tweet-text tweet-te...  \n",
      "4  <p class=\"TweetTextSize js-tweet-text tweet-te...  \n"
     ]
    }
   ],
   "source": [
    "# save output as df \n",
    "\n",
    "list_tweets = [list(elem.values()) for elem in list_of_encoded_tweets]\n",
    "list_columns = list(list_of_encoded_tweets[0].keys())\n",
    "df = pd.DataFrame(list_tweets, columns = list_columns)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Output as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to csv file\n",
    "\n",
    "df.to_csv(r'cibc_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Output as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output as JSON file\n",
    "#jsonfile = open('cibc_tweets.json','w')\n",
    "#json.dump(list_of_encoded_tweets, jsonfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using CLI/Anaconda Command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's easier to save a file as json or csv using CLI. Here's an exmaple.\n",
    "<br>\n",
    "For example: \n",
    "<br>\n",
    "1) twitterscraper \"#cibc\" -l 100 -bd 2017-01-01 -ed 2017-06-01 -o cibc_tweets.csv -c\n",
    "<br>\n",
    "2) twitterscraper \"#cibc or @cibc\" -l 100 -bd 2017-01-01 -ed 2017-06-01 -p 10 -o cibc_tweets.json\n",
    "<br>\n",
    "<br>\n",
    "For more info, go to https://github.com/taspinar/twitterscraper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
